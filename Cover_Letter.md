# Cover Letter

**Date:** December 14, 2025

**To:** Dr. Kevin C. Chung, M.D., M.S.
Editor-in-Chief
*Plastic and Reconstructive Surgery*

**From:** Richard J. Redett, MD (Corresponding Author)
Department of Plastic and Reconstructive Surgery
Johns Hopkins University School of Medicine
Baltimore, MD, USA
Email: rredett1@jhmi.edu

**Re:** PRS-D-24-02344 — Revised Manuscript Submission
**Title:** From Months to Minutes: Evaluating an AI-Driven Approach to Systematic Reviews in Plastic Surgery

---

Dear Dr. Chung,

On behalf of my co-authors, I am pleased to resubmit our revised manuscript for *Plastic and Reconstructive Surgery*. We are grateful for the thoughtful and constructive feedback from the reviewers and have carefully addressed every comment through extensive revisions that we believe substantially strengthen the manuscript.

**Summary of Significance**

Our integrated search-and-screening workflow reduces systematic review screening time from 40–80 hours to minutes while maintaining clinical-grade rigor (≥99% recall with 100% accuracy on eligible studies) and lowering costs by >99% compared with dual-reviewer workflows. The study demonstrates how plastic surgery–specific criteria, when encoded by experts and executed by AI, enable reliable, reproducible evidence synthesis across microsurgery, reconstructive, aesthetic, and outcomes research topics.

**Response to Reviewer Concerns**

We have thoroughly revised the manuscript to address all reviewer comments. Below is a summary of the key changes:

**Reviewer #1 - Comparison with Existing Tools, Visualization, and Clinical Relevance:**
- Added comprehensive comparison with ASReview, RobotReviewer, and Rayyan in the Discussion, contextualizing our workflow's advantages and limitations within the broader landscape of AI-assisted systematic review tools
- Redesigned Figure 1 to clearly illustrate the two-stage workflow (coarse-grained and fine-grained screening) and added Figures 2–4 showing the refinement process, gold standard recall validation, and performance metrics across reviews
- Strengthened the clinical take-home message throughout, emphasizing that AI serves as an augmentation tool rather than replacement for expert judgment, with clear discussion of error analysis and the critical human-in-the-loop role
- Provided detailed analysis of AI limitations, including the lower precision in the facial nerve grading review attributed to ambiguous language, and discussed implications for complex medical terminology

**Reviewer #2 - Reproducibility, Multilingual Capacity, and Ethics:**
- Added detailed examples in Supplementary Tables S1 (inclusion/exclusion criteria for all 4 reviews) and S2 (AI screening decisions with per-criterion reasoning), providing step-by-step guidance for readers unfamiliar with this process
- Published complete screening configurations in the GitHub repository to enable full reproducibility
- Addressed multilingual screening capacity, noting that while our current implementation focused on English and Chinese literature, modern LLMs support 100+ languages with appropriate prompt engineering
- Added discussion of intellectual property and ethics considerations in the limitations section, addressing ongoing issues with generative AI tools in academic research and the importance of institutional guidance on content permissions

**Reviewer #3 - Outcome Metrics, Methodology Clarity, and Future Directions:**
- Expanded explanation of all outcome measures (sensitivity, specificity, PPV, NPV, precision, recall, F1 score) in the Methods section with clear derivations and clinical interpretation for readers unfamiliar with information retrieval metrics
- Added 95% confidence intervals for all performance metrics and streamlined Results to present key findings concisely
- Clarified that our study focused on validating the screening phase specifically, with detailed description of how we replicated each original systematic review (exact databases, date ranges, and Boolean search strings documented in Methods)
- Released complete screening code, validation results, and analysis scripts in a GitHub repository for full scientific reproducibility
- Documented prompt development time (2–4 hours per review) as part of the overall workflow efficiency analysis
- Added discussion of living systematic review capabilities, noting potential for automated monthly updates to maintain current evidence
- Addressed transparency regarding LLM versions, parameters, and costs in Supplementary Table S3

**Key Structural Improvements:**
- Introduced plastic surgery–specific rationale and explicit study questions in the Introduction per Reviewer #3's suggestions
- Reorganized tables and figures to eliminate redundancy (merged overlapping content from Table 1/Figure 2 and Tables 3/4)
- All revisions marked in red text throughout the manuscript per journal instructions

**Enclosures Included in This Submission Package**
- Manuscript.docx — Revised manuscript with changes marked in red text
- Response_to_Reviewers.docx — Point-by-point responses to all reviewer comments
- Table 1.docx — Systematic Review Characteristics
- Table 2.docx — AI Screening Performance Metrics
- Figure 1.tiff — Two-Stage Screening Workflow (300 DPI)
- Figure 2.tiff — Two-Stage Refinement (300 DPI)
- Figure 3.tiff — Gold Standard Recall (300 DPI)
- Figure 4.tiff — Performance Metrics Panel (300 DPI)
- Supplementary_Table_S1.docx — Inclusion/Exclusion Criteria for All Reviews
- Supplementary_Table_S2.docx — Example AI Screening Decisions with Reasoning
- Supplementary_Table_S3.docx — Large Language Model Specifications
- GitHub repository: https://github.com/Shakes-tzd/months-to-minutes-prs

**Statement of Originality and Compliance**

This work is original, not under consideration elsewhere, and all authors have approved this submission. The authors declare no conflicts of interest. Funding sources are detailed in the manuscript.

**Conclusion**

We believe these comprehensive revisions have substantially strengthened the manuscript by enhancing reproducibility, clarifying methodology, expanding comparative analysis, and addressing important ethical considerations. The additions make our AI-assisted screening workflow more accessible to plastic surgery researchers while maintaining scientific rigor. We are confident that this revised manuscript addresses all reviewer concerns and will be of significant interest to the PRS readership.

Thank you for the opportunity to revise and resubmit. We look forward to your re-evaluation.

Sincerely,

Richard J. Redett, MD  
Department of Plastic and Reconstructive Surgery  
Johns Hopkins University School of Medicine  
601 North Caroline St, Baltimore, MD 21287  
Email: rredett1@jhmi.edu
